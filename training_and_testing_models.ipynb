{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ce8a1bbc-8f0c-4e01-b890-8dfc5dd200c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11040 files belonging to 7 classes.\n",
      "Found 1231 files belonging to 7 classes.\n",
      "Found 3068 files belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "from load_data import load_data\n",
    "\n",
    "train_data, val_data, test_data = load_data('RAF_DB', rgb=True, image_size=(100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec45cc12-4dd6-48a1-946f-2a8f71b29fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do zrobienia - puszczenie jeszcze jakiegos keras_tune, ale moze troszke bardziej sensownego i sprobowanie lekkiego stunowania strukturki\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow as tf \n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(7, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ef73d40-f58c-4030-bb73-d39eeac2c084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-28 16:31:32.001993: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_1/dropout_4/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-04-28 16:31:33.692325: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600\n",
      "2024-04-28 16:31:34.855482: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-04-28 16:31:34.859194: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f344f6ef2a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-04-28 16:31:34.859225: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2024-04-28 16:31:34.863181: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-04-28 16:31:34.950084: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 17s 26ms/step - loss: 2.0204 - accuracy: 0.3132 - val_loss: 1.5340 - val_accuracy: 0.4168 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "404/404 [==============================] - 10s 25ms/step - loss: 1.4798 - accuracy: 0.4516 - val_loss: 1.3846 - val_accuracy: 0.4736 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "404/404 [==============================] - 10s 25ms/step - loss: 1.3103 - accuracy: 0.5033 - val_loss: 1.2953 - val_accuracy: 0.5118 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "404/404 [==============================] - 10s 25ms/step - loss: 1.2143 - accuracy: 0.5382 - val_loss: 1.1776 - val_accuracy: 0.5623 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "404/404 [==============================] - 10s 25ms/step - loss: 1.1424 - accuracy: 0.5681 - val_loss: 1.2098 - val_accuracy: 0.5567 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "404/404 [==============================] - 10s 25ms/step - loss: 1.0893 - accuracy: 0.5910 - val_loss: 1.1194 - val_accuracy: 0.5825 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "404/404 [==============================] - 10s 25ms/step - loss: 1.0424 - accuracy: 0.6073 - val_loss: 1.1657 - val_accuracy: 0.5772 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "404/404 [==============================] - 10s 25ms/step - loss: 0.9842 - accuracy: 0.6369 - val_loss: 1.1670 - val_accuracy: 0.5588 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "402/404 [============================>.] - ETA: 0s - loss: 0.9337 - accuracy: 0.6540\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "404/404 [==============================] - 10s 25ms/step - loss: 0.9330 - accuracy: 0.6543 - val_loss: 1.1232 - val_accuracy: 0.5880 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "404/404 [==============================] - 11s 26ms/step - loss: 0.7724 - accuracy: 0.7156 - val_loss: 1.1207 - val_accuracy: 0.6082 - lr: 5.0000e-04\n",
      "Epoch 11/50\n",
      "404/404 [==============================] - 11s 26ms/step - loss: 0.6907 - accuracy: 0.7459 - val_loss: 1.1490 - val_accuracy: 0.6117 - lr: 5.0000e-04\n",
      "Epoch 12/50\n",
      "404/404 [==============================] - ETA: 0s - loss: 0.6186 - accuracy: 0.7724\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "404/404 [==============================] - 11s 26ms/step - loss: 0.6186 - accuracy: 0.7724 - val_loss: 1.1857 - val_accuracy: 0.6089 - lr: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# Model training\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from config import BATCH_SIZE, EPOCHS\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "best_model_path = 'models/best_fer_no_aug.h5'\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=1, factor=0.5, min_lr=0.00001)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "train_history = model.fit(train_data, batch_size = BATCH_SIZE, epochs = EPOCHS, validation_data=val_data, callbacks = [earlystop, learning_rate_reduction])\n",
    "\n",
    "model.save_weights(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "feb403ff-2373-4e4a-ab46-383ea2a3c127",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_9\" is incompatible with the layer: expected shape=(None, 48, 48, 3), found shape=(None, 100, 100, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata_set_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TestDataMetrics\n\u001b[1;32m      4\u001b[0m tdm \u001b[38;5;241m=\u001b[39m TestDataMetrics(test_data, model)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtdm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_confusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mevaluate(test_data)\n",
      "File \u001b[0;32m/workspace/data_set_utils.py:83\u001b[0m, in \u001b[0;36mTestDataMetrics.print_confusion_matrix\u001b[0;34m(self, normalize)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_confusion_matrix\u001b[39m(\u001b[38;5;28mself\u001b[39m, normalize: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 83\u001b[0m     cm \u001b[38;5;241m=\u001b[39m confusion_matrix(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictions\u001b[49m)\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m normalize:\n\u001b[1;32m     85\u001b[0m         cm \u001b[38;5;241m=\u001b[39m cm\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m/\u001b[39m cm\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[:, np\u001b[38;5;241m.\u001b[39mnewaxis]\n",
      "File \u001b[0;32m/workspace/data_set_utils.py:65\u001b[0m, in \u001b[0;36mTestDataMetrics.predictions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredictions\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__test_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msilent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filehpjffeqj.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_9\" is incompatible with the layer: expected shape=(None, 48, 48, 3), found shape=(None, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "# model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "#model.load_weights('models/unkown_best_fer_no_aug.h5')\n",
    "from data_set_utils import TestDataMetrics\n",
    "tdm = TestDataMetrics(test_data, model)\n",
    "tdm.print_confusion_matrix()\n",
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96feb95-85a0-4f8b-aeae-fc1016a3876b",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------\n",
    "GRID SEARCH BASED ON INITIAL NETWORK, BASED ON WHITCH THE MODEL ABOVE HAVE BEEN TWEAKED:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f08c9a0a-33e4-4c65-9181-ef3813e83277",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner import HyperModel\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "class CNNHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = Sequential()\n",
    "        # Dodaj warstwy konwolucyjne z możliwością wyboru liczby filtrów\n",
    "        for i in range(hp.Int('conv_blocks', 3, 5, default=4)):\n",
    "            filters = hp.Choice(f'filters_{i}', [32, 64, 128, 256])\n",
    "            activation = hp.Choice('activation', ['relu', 'softmax'])\n",
    "            for _ in range(2):  # Dwie warstwy konwolucyjne na blok\n",
    "                model.add(Conv2D(filters=filters, kernel_size=(3, 3), activation=activation, padding='same'))\n",
    "                model.add(BatchNormalization())\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "            model.add(Dropout(rate=hp.Float('dropout_conv', min_value=0.2, max_value=0.3, step=0.05)))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        # Warstwa gęsta na końcu\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        model.add(Dropout(rate=hp.Float('dropout_dense', min_value=0.3, max_value=0.5, step=0.05)))\n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3096a183-b854-445c-b3a4-19fc758f2c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from trial_dir/hparam_tuning/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "from keras_tuner import RandomSearch\n",
    "\n",
    "# Ustawienie rozmiaru wejścia i liczby klas\n",
    "hypermodel = CNNHyperModel(input_shape=(100, 100, 1), num_classes=7)\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    hypermodel,\n",
    "    objective='val_loss',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory='trial_dir',\n",
    "    project_name='hparam_tuning'\n",
    ")\n",
    "\n",
    "tuner.search(train_data,\n",
    "             epochs=10, \n",
    "             validation_data=val_data\n",
    "            )\n",
    "\n",
    "# Pobranie najlepszego modelu\n",
    "best_model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b475dab-2787-4b72-b662-d340f7e270cd",
   "metadata": {},
   "source": [
    "---------------------------------------------------\n",
    "BASE RESNET50 code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9044ceb0-0249-4a18-912c-69dba611fd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50, ResNet50V2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "ResNet = ResNet50V2(weights='imagenet', include_top=False, input_shape=(100, 100, 3))\n",
    "ResNet.trainable = True\n",
    "\n",
    "model = Sequential([\n",
    "    ResNet,\n",
    "    Flatten(),\n",
    "    Dense(7, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9caf62da-955c-4780-8266-632dbf174cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "173/173 [==============================] - 369s 2s/step - loss: 1.1481 - accuracy: 0.6195 - val_loss: 6.9572 - val_accuracy: 0.6434 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "173/173 [==============================] - 310s 2s/step - loss: 0.6776 - accuracy: 0.7607 - val_loss: 0.8977 - val_accuracy: 0.7132 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "173/173 [==============================] - 307s 2s/step - loss: 0.4882 - accuracy: 0.8287 - val_loss: 1.0788 - val_accuracy: 0.6742 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 0.7205 - accuracy: 0.7579\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "173/173 [==============================] - 307s 2s/step - loss: 0.7205 - accuracy: 0.7579 - val_loss: 7132.3608 - val_accuracy: 0.3875 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "173/173 [==============================] - 312s 2s/step - loss: 0.7952 - accuracy: 0.7478 - val_loss: 0.8696 - val_accuracy: 0.7124 - lr: 5.0000e-04\n",
      "Epoch 6/50\n",
      "173/173 [==============================] - 316s 2s/step - loss: 0.4715 - accuracy: 0.8356 - val_loss: 0.7506 - val_accuracy: 0.7457 - lr: 5.0000e-04\n",
      "Epoch 7/50\n",
      "173/173 [==============================] - 314s 2s/step - loss: 0.2435 - accuracy: 0.9177 - val_loss: 0.7067 - val_accuracy: 0.7799 - lr: 5.0000e-04\n",
      "Epoch 8/50\n",
      "173/173 [==============================] - 316s 2s/step - loss: 0.1062 - accuracy: 0.9624 - val_loss: 0.9754 - val_accuracy: 0.7441 - lr: 5.0000e-04\n",
      "Epoch 9/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 0.1103 - accuracy: 0.9624\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "173/173 [==============================] - 314s 2s/step - loss: 0.1103 - accuracy: 0.9624 - val_loss: 0.9961 - val_accuracy: 0.7831 - lr: 5.0000e-04\n",
      "Epoch 10/50\n",
      "173/173 [==============================] - 313s 2s/step - loss: 0.0364 - accuracy: 0.9893 - val_loss: 0.7961 - val_accuracy: 0.8115 - lr: 2.5000e-04\n",
      "Epoch 11/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9978\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002.\n",
      "173/173 [==============================] - 310s 2s/step - loss: 0.0091 - accuracy: 0.9978 - val_loss: 0.8076 - val_accuracy: 0.8188 - lr: 2.5000e-04\n",
      "Epoch 12/50\n",
      "173/173 [==============================] - 310s 2s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8730 - val_accuracy: 0.8123 - lr: 2.0000e-04\n",
      "Epoch 13/50\n",
      "173/173 [==============================] - 311s 2s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8840 - val_accuracy: 0.8091 - lr: 2.0000e-04\n",
      "Epoch 14/50\n",
      "173/173 [==============================] - 310s 2s/step - loss: 8.5678e-04 - accuracy: 1.0000 - val_loss: 0.9048 - val_accuracy: 0.8107 - lr: 2.0000e-04\n",
      "Epoch 15/50\n",
      "173/173 [==============================] - 310s 2s/step - loss: 6.4968e-04 - accuracy: 1.0000 - val_loss: 0.9160 - val_accuracy: 0.8172 - lr: 2.0000e-04\n",
      "Epoch 16/50\n",
      "173/173 [==============================] - 309s 2s/step - loss: 4.8750e-04 - accuracy: 1.0000 - val_loss: 0.9240 - val_accuracy: 0.8140 - lr: 2.0000e-04\n",
      "Epoch 17/50\n",
      "173/173 [==============================] - ETA: 0s - loss: 3.8100e-04 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 11.\n",
      "173/173 [==============================] - 305s 2s/step - loss: 3.8100e-04 - accuracy: 1.0000 - val_loss: 0.9392 - val_accuracy: 0.8164 - lr: 2.0000e-04\n",
      "Epoch 17: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from config import BATCH_SIZE, EPOCHS\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "best_model_path = 'models/base_flaten_res_raf.h5'\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_accuracy', patience=6, restore_best_weights=True, verbose=1)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience=2, verbose=1, factor=0.5, min_lr=0.0002)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "train_history = model.fit(train_data, batch_size = BATCH_SIZE, epochs = EPOCHS, validation_data=val_data, callbacks = [earlystop, learning_rate_reduction])\n",
    "\n",
    "model.save_weights(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc01522d-2b10-41bf-81a7-6a2664e87c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_set_utils import plot_loss_and_acc\n",
    "plot_loss_and_acc(train_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b7f05f-2c04-40f8-b716-64ae11ea8d29",
   "metadata": {},
   "source": [
    "-----------------------------------------------\n",
    "TUNED RESNET50 CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3e6150-4b3b-4ac6-8ec2-99201de0f539",
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet = ResNet50V2(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
    "ResNet.trainable = True\n",
    "\n",
    "for layer in ResNet.layers[:-50]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model = Sequential([\n",
    "    ResNet,\n",
    "    Dropout(.25),\n",
    "    BatchNormalization(),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(.5),\n",
    "    Dense(7,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b808a850-4cb6-47ae-bf21-672b033f9558",
   "metadata": {},
   "outputs": [],
   "source": [
    "from "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
